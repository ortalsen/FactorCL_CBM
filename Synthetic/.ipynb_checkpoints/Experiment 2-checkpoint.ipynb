{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2e1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f68cbbe36d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import*\n",
    "from synthetic_concept_model import *\n",
    "from synthetic_coop_model import *\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "random.seed(7)\n",
    "numpy.random.seed(seed=7)\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479b8138-eebc-41d8-a4a6-bf778329e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454ff7e",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3a5653",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim_info = dict()\n",
    "label_dim_info = dict()\n",
    "transform_dim = 100000\n",
    "\n",
    "intersections = get_intersections(num_modalities=2)\n",
    "\n",
    "feature_dim_info['12'] = 10\n",
    "feature_dim_info['1'] = 6\n",
    "feature_dim_info['2'] = 6\n",
    "\n",
    "label_dim_info['12'] = 10\n",
    "label_dim_info['1'] = 6\n",
    "label_dim_info['2'] = 6\n",
    "num_concepts = 1\n",
    "transforms_2concept = None\n",
    "transforms_2hd = None\n",
    "num_data = 10000\n",
    "noise=0.3\n",
    "pos_prob=0.5\n",
    "# total_data, total_labels, total_concepts, total_raw_features = generate_data_concepts(num_data, num_concepts,\n",
    "                                                                                     #  feature_dim_info,\n",
    "                                                                                     #  label_dim_info,\n",
    "                                                                                     #  transform_dim=transform_dim,\n",
    "                                                                                     # noise=noise,\n",
    "                                                                                     # pos_prob=pos_prob)\n",
    "\n",
    "# synth_data_dict = {'total_data':total_data, 'total_labels':total_labels, 'total_concepts':total_concepts, 'total_raw_features':total_raw_features}\n",
    "# synth_data_file_name = '../synth_data/'+'synth_data_exp2_'+str(noise)+'_'+str(pos_prob)+'.pkl'\n",
    "# pickle.dump(synth_data_dict, open(synth_data_file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968974b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting & loading\n",
    "synth_data_dict = pickle.load(open('../synth_data/'+'synth_data_exp2_'+str(noise)+'_'+str(pos_prob)+'.pkl', 'rb'))\n",
    "total_data = synth_data_dict['total_data']\n",
    "total_labels = synth_data_dict['total_labels']\n",
    "total_concepts = synth_data_dict['total_concepts']\n",
    "total_raw_features = synth_data_dict['total_raw_features']\n",
    "\n",
    "dataset = MultiConcept(total_data, total_labels, total_concepts, 0)\n",
    "batch_size = 100\n",
    "trainval_dataset, test_dataset = torch.utils.data.random_split(dataset,  \n",
    "                                                            [int(0.8 * num_data), num_data - int(0.8 * num_data)])\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset,\n",
    "                                                           [int(0.8 * len(trainval_dataset)), len(trainval_dataset) - int(0.8 * len(trainval_dataset))])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
    "                          batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4059c6-b3f0-4fc7-a4c4-291f4e518a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_dim = 101024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31d4dc",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801734b-005d-4068-bbe0-8f19021e0c67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scenario 1\n",
    "Pretrain on a large dataset $D_L:=\\{x_i,c_i\\}$ by minimizing InfoNCE_CLUB between $(Z_{\\bar{c}},c|x)$ and fine-tune on small dataset $D_S:=\\{x_j,y_j\\}$ with supervised learning $x \\rightarrow Z_{\\bar{c}} \\rightarrow y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce0ace-a2be-4652-bbc3-c167566d697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptCLSUP_Pretrain(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, embed_dim, layers=2, activation='relu', lr=1e-4):\n",
    "        super(ConceptCLSUP_Pretrain, self).__init__()\n",
    "        self.critic_hidden_dim = 512\n",
    "        self.critic_layers = 1\n",
    "        self.critic_activation = 'relu'\n",
    "        self.lr = lr\n",
    "\n",
    "        # encoders\n",
    "        self.backbone = mlp(x_dim, hidden_dim, embed_dim, layers, activation)\n",
    "        self.linears_infonce = mlp(embed_dim, embed_dim, embed_dim, 1, activation) \n",
    "\n",
    "        # critics\n",
    "        concept_dim = 1\n",
    "        self.club_critic = CLUBInfoNCECritic(embed_dim + x_dim, concept_dim, self.critic_hidden_dim, self.critic_layers, self.critic_activation)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        # compute embedding\n",
    "        z = self.linears_infonce(self.backbone(x))\n",
    "        # compute critic scores\n",
    "        club_infonce_score = self.club_critic(torch.cat([z, x], dim=-1), c)\n",
    "        return club_infonce_score\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def get_backbone(self):\n",
    "        return self.backbone\n",
    "    \n",
    "\n",
    "def train_concept_informed_Pretrain_model(concept_encoder, model, train_loader,val_loader, num_epochs, device, lr, log_interval,\n",
    "                          save_interval, save_path):\n",
    "\n",
    "    concept_encoder.eval()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_err = torch.tensor(1e7)\n",
    "    tepoch = tqdm(range(num_epochs))\n",
    "    for epoch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        for batch_idx, (data, concept, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            c, z_c = concept_encoder(data)\n",
    "            loss = model(data, c) #z_c\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        tepoch.set_postfix(loss=loss.item())\n",
    "        if epoch % save_interval == 0:\n",
    "            val_err = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, concept, target) in enumerate(val_loader):\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    c , z_c = concept_encoder(data)\n",
    "                    output = model(data, c) #z_c\n",
    "                    val_err += output\n",
    "                val_err = val_err / len(val_loader)\n",
    "            if val_err < best_val_err:\n",
    "                best_val_err = val_err\n",
    "\n",
    "            else:\n",
    "                print('Val loss did not improve')\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'concept_informed_model.pth'))\n",
    "                return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e160d497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_dim = 512\n",
    "embed_dim = 50 \n",
    "concept_encoder = ConceptEncoder(transform_dim, embed_dim,hidden_dim, critic_hidden_dim=512, critic_layers=1, layers=1).to(device)\n",
    "model = ConceptCLSUP_Pretrain(transform_dim, hidden_dim, embed_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b2906-125a-4b67-8888-58e81d96ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train concpet encoder\n",
    "trained_concept_encoder = train_concept_encoder(concept_encoder, train_loader,val_loader, transform_dim, device, 1e-5, 1e-5, 25, 3, '../trained_models')\n",
    "# train concept informed model\n",
    "trained_concept_informed_Pretrain_model = train_concept_informed_Pretrain_model(trained_concept_encoder, model, train_loader, val_loader, 100, device, 1e-5, 25, 3, '../trained_models')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "738cfac9-dd11-4960-a047-199455cece76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#New test split\n",
    "num_data = len(test_dataset)\n",
    "batch_size = 100\n",
    "new_trainval_dataset, new_test_dataset = torch.utils.data.random_split(test_dataset,  \n",
    "                                                            [int(0.5 * num_data), num_data - int(0.5 * num_data)])\n",
    "new_train_dataset, new_val_dataset = torch.utils.data.random_split(new_trainval_dataset,\n",
    "                                                           [int(0.8 * len(new_trainval_dataset)), len(new_trainval_dataset) - int(0.8 * len(new_trainval_dataset))])\n",
    "\n",
    "new_train_loader = DataLoader(new_train_dataset, shuffle=True, drop_last=True,\n",
    "                          batch_size=batch_size)\n",
    "new_val_loader = DataLoader(new_val_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "new_test_loader = DataLoader(new_test_dataset, shuffle=False, drop_last=False)\n",
    "\n",
    "#Train Final Model\n",
    "\n",
    "backbone = trained_concept_informed_Pretrain_model.get_backbone()\n",
    "new_model = nn.Sequential(backbone, mlp(50, 256, 1, 1, activation= 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7d76b41-d6d2-44fe-8b76-69d675a988e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200:  20%|██        | 200/1000 [01:42<06:51,  1.95it/s, loss=0.000801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n",
      "Accuracy: 0.694\n",
      "Precision: 0.6555023923444976\n",
      "Recall: 0.8203592814371258\n",
      "F1-score: 0.728723404255319\n"
     ]
    }
   ],
   "source": [
    "from baselines import*\n",
    "\n",
    "final_model = mlp_train(new_model, new_train_loader, new_val_loader, 1000, 1e-5, 1e-5,'cuda', 100, 100)\n",
    "\n",
    "test_embeds = torch.stack([sample[0] for sample in  new_test_dataset]).detach().cpu().numpy()\n",
    "test_concepts = torch.tensor([sample[1].item() for sample in  new_test_dataset]).unsqueeze(1)\n",
    "test_labels = np.array([sample[-1].item() for sample in  new_test_dataset])\n",
    "    \n",
    "out = final_model(torch.tensor(test_embeds).to(device))\n",
    "predictions = torch.sigmoid(out).round().detach().cpu().numpy()\n",
    "        \n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0c20c-e369-45fc-a87f-e68c325cc0c2",
   "metadata": {},
   "source": [
    "## Scenario 2\n",
    "Pretrain on a large dataset $D_L:=\\{x_i,c_i\\}$ by both minimizing InfoNCE_CLUB between $(Z_{\\bar{c}},c|x)$ and maximizing \n",
    "InfoNCE$(c,Z_c|x)$.\n",
    "Proceed to fine-tune on small dataset $D_S:=\\{x_j,y_j\\}$ with supervised learning $x \\rightarrow Z_{\\bar{c}}, Z_c \\rightarrow y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6904ea6-0ba8-48ad-b6ad-27cfc2f35eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptCLSUP_Pretrain_Sc2(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, embed_dim, layers=2, activation='relu', lr=1e-4, concept_dim=1):\n",
    "        super(ConceptCLSUP_Pretrain, self).__init__()\n",
    "        self.critic_hidden_dim = 512\n",
    "        self.critic_layers = 1\n",
    "        self.critic_activation = 'relu'\n",
    "        self.lr = lr\n",
    "\n",
    "        # encoders\n",
    "        self.backbone = mlp(x_dim, hidden_dim, embed_dim, layers, activation)\n",
    "        self.linears_club = mlp(embed_dim, embed_dim, embed_dim, 1, activation) \n",
    "        self.linears_infonce = mlp(embed_dim, embed_dim, embed_dim, 1, activation) \n",
    "\n",
    "        # critics\n",
    "        self.club_critic = CLUBInfoNCECritic(embed_dim + x_dim, concept_dim, self.critic_hidden_dim, self.critic_layers, self.critic_activation)\n",
    "        self.nce_critic = InfoNCECritic(embed_dim + x_dim, concept_dim, self.critic_hidden_dim, self.critic_layers, self.critic_activation)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        # compute embedding\n",
    "        z_comp = self.linears_club(self.backbone(x))\n",
    "        z_c = self.linears_infonce(self.backbone(x))\n",
    "        # compute critic scores\n",
    "        club_infonce_score = self.club_critic(torch.cat([z_comp, x], dim=-1), c)\n",
    "        infonce_score = self.nce_critic(torch.cat([z_c, x], dim=-1), c)\n",
    "        \n",
    "        return  club_infonce_score + infonce_score\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        #what should the embedding be?\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def get_backbone(self):\n",
    "        return self.backbone\n",
    "    \n",
    "\n",
    "def train_concept_informed_Pretrain_model(concept_encoder, model, train_loader,val_loader, num_epochs, device, lr, log_interval,\n",
    "                          save_interval, save_path):\n",
    "\n",
    "    concept_encoder.eval()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_err = torch.tensor(1e7)\n",
    "    tepoch = tqdm(range(num_epochs))\n",
    "    for epoch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        for batch_idx, (data, concept, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            c, z_c = concept_encoder(data)\n",
    "            loss = model(data, c) #z_c\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        tepoch.set_postfix(loss=loss.item())\n",
    "        if epoch % save_interval == 0:\n",
    "            val_err = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, concept, target) in enumerate(val_loader):\n",
    "                    data, target = data.to(device), target.to(device)\n",
    "                    c , z_c = concept_encoder(data)\n",
    "                    output = model(data, c) #z_c\n",
    "                    val_err += output\n",
    "                val_err = val_err / len(val_loader)\n",
    "            if val_err < best_val_err:\n",
    "                best_val_err = val_err\n",
    "\n",
    "            else:\n",
    "                print('Val loss did not improve')\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'concept_informed_model.pth'))\n",
    "                return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b6aa1-aa0b-4f1b-860a-7bc0dbdcaf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afcb2c4c-cb3b-4d83-96ee-7cda51c7b503",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Baseline (Pre-Training with Concepts $x \\rightarrow c_1, x \\rightarrow y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e24d089-bb3f-445b-a17a-66ce1579d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200:  20%|██        | 200/1000 [32:32<2:10:10,  9.76s/it, loss=0.00038] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200:  20%|██        | 200/1000 [03:54<15:37,  1.17s/it, loss=2.81e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.904\n",
      "Precision: 0.8802919708029197\n",
      "Recall: 0.9773095623987034\n",
      "F1-score: 0.9262672811059907\n"
     ]
    }
   ],
   "source": [
    "# train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
    "#                           batch_size=batch_size)\n",
    "# val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "# test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False)\n",
    "\n",
    "backbone = mlp(transform_dim, 512, 1, layers=3, activation='relu')\n",
    "trained_backbone = mlp_train_c(backbone, train_loader, val_loader, 1000, 1e-5, 1e-5,'cuda', 100, 100)\n",
    "FC = mlp(1, 256, 1, 1, activation= 'relu')\n",
    "model = nn.Sequential(trained_backbone, FC)\n",
    "trained_model = mlp_train(model, new_train_loader, new_val_loader, 1000, 1e-5, 1e-5,'cuda', 100, 100)\n",
    "\n",
    "test_embeds = torch.stack([sample[0] for sample in  new_test_dataset]).detach().cpu().numpy()\n",
    "out = trained_model(torch.tensor(test_embeds).to(device))\n",
    "predictions = torch.sigmoid(out).round().detach().cpu().numpy()\n",
    "        \n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "precision = precision_score(test_labels, predictions)\n",
    "recall = recall_score(test_labels, predictions)\n",
    "f1 = f1_score(test_labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6f674-9193-4c74-a297-df000308ee21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da6791-e4a8-49b9-bf8e-f284b29c8f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
