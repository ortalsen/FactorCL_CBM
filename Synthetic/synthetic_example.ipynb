{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTEV_elPBK32",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#FactorCL on Synthetic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHKnbVkoASPI",
    "outputId": "c0e82d17-f04a-4550-96f6-bf60af567c61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FactorCL'...\n",
      "remote: Enumerating objects: 150, done.\u001b[K\n",
      "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
      "remote: Total 150 (delta 13), reused 2 (delta 0), pack-reused 116\u001b[K\n",
      "Receiving objects: 100% (150/150), 321.78 KiB | 3.04 MiB/s, done.\n",
      "Resolving deltas: 100% (70/70), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pliang279/FactorCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_UCHEyzAbYQ",
    "outputId": "21e1d2a8-4e84-4bfc-b15f-cee17d7da7e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/FactorCL_CBM/Synthetic/FactorCL\n"
     ]
    }
   ],
   "source": [
    "%cd FactorCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A0mgHF3bAgvo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Synthetic.dataset import*\n",
    "from synthetic_model import*\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5RWziN1_ANhB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hidden_dim=512\n",
    "embed_dim=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glk_GDn0AEvs",
    "outputId": "faacc9a2-e622-49be-c4e4-0e1f690cf0a7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '12']\n",
      "{'12': 10, '1': 6, '2': 6}\n",
      "{'12': 10, '1': 6, '2': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define custom dimensions of features and labels\n",
    "feature_dim_info = dict()\n",
    "label_dim_info = dict()\n",
    "\n",
    "intersections = get_intersections(num_modalities=2)\n",
    "\n",
    "feature_dim_info['12'] = 10\n",
    "feature_dim_info['1'] = 6\n",
    "feature_dim_info['2'] = 6\n",
    "\n",
    "label_dim_info['12'] = 10\n",
    "label_dim_info['1'] = 6\n",
    "label_dim_info['2'] = 6\n",
    "\n",
    "print(intersections)\n",
    "print(feature_dim_info)\n",
    "print(label_dim_info)\n",
    "\n",
    "# Get datasets\n",
    "total_data, total_labels, total_raw_features = generate_data(30000, 2, feature_dim_info, label_dim_info)\n",
    "total_labels = get_labels(label_dim_info, total_raw_features)\n",
    "\n",
    "dataset = MultimodalDataset(total_data, total_labels)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 256\n",
    "num_data = total_labels.shape[0]\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8*num_data), num_data-int(0.8*num_data)])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
    "                            batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False,\n",
    "                            batch_size=batch_size)\n",
    "data_loader = DataLoader(dataset, shuffle=False, drop_last=False,\n",
    "                            batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzKxUpkiwzhb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##Linear Probing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP_E2H4EBnsh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###FactorCL-SUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUrkdAhgAPgJ",
    "outputId": "0e02ddd8-9388-46e1-fdb6-4aa97bfcbdf0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m factorcl_sup \u001b[38;5;241m=\u001b[39m FactorCLSUP(\u001b[43mA_dim\u001b[49m, B_dim, \u001b[38;5;241m20\u001b[39m, hidden_dim, embed_dim)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      2\u001b[0m train_sup_model(factorcl_sup, train_loader, dataset, num_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_club_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m factorcl_sup\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A_dim' is not defined"
     ]
    }
   ],
   "source": [
    "factorcl_sup = FactorCLSUP(A_dim, B_dim, 20, hidden_dim, embed_dim).cuda()\n",
    "train_sup_model(factorcl_sup, train_loader, dataset, num_epoch=10, num_club_iter=1)\n",
    "factorcl_sup.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ril93KsbBeHZ",
    "outputId": "e99477e0-9e3e-4748-fca8-5d05ccb8aa14",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Simple evaluation using linear logistic regression model\n",
    "\n",
    "# Embeddings\n",
    "train_embeds = factorcl_sup.get_embedding(torch.stack(train_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "train_labels = train_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "test_embeds = factorcl_sup.get_embedding(torch.stack(test_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "test_labels = test_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "# Train Logistic Classifier\n",
    "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
    "score = clf.score(test_embeds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhFO10gs272V",
    "outputId": "899044cb-8c97-4d8f-b555-5f4643e8f234",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_gdUqNO5NYM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###FactorCL-SSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqCK0pyg5NYS",
    "outputId": "b441fbac-ee51-4e7a-ccbe-1bce52fcece4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "factorcl_ssl = FactorCLSSL(A_dim, B_dim, hidden_dim, embed_dim).cuda()\n",
    "train_sup_model(factorcl_ssl, train_loader, dataset, num_epoch=10, num_club_iter=1)\n",
    "factorcl_ssl.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpvNxNwG5NYS",
    "outputId": "5a7075d7-8f47-43b5-d6de-5be795807bed",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Simple evaluation using linear logistic regression model\n",
    "\n",
    "# Embeddings\n",
    "train_embeds = factorcl_ssl.get_embedding(torch.stack(train_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "train_labels = train_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "test_embeds = factorcl_ssl.get_embedding(torch.stack(test_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "test_labels = test_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "# Train Logistic Classifier\n",
    "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
    "score = clf.score(test_embeds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iHDduqL5NYS",
    "outputId": "adcf6b83-c595-49c3-a7c7-9f3363670ab2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6icituq2Hkra",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pYPGQgNHiPN",
    "outputId": "f6bd0c12-f1f8-46c0-df8a-3856ee57effe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set use_label=True for SupCon model\n",
    "simclr_model = SupConModel(A_dim, B_dim, hidden_dim, embed_dim, use_label=False).cuda()\n",
    "simclr_optim = optim.Adam(simclr_model.parameters(), lr=lr)\n",
    "train_supcon(simclr_model, train_loader, simclr_optim, num_epoch=20)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvHpTE5gHoi6",
    "outputId": "7128738e-9cd0-4c3c-b288-62f83bb8da8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_embeds = simclr_model.get_embedding(torch.stack(train_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "train_labels = train_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "# Embeddings\n",
    "test_embeds = simclr_model.get_embedding(torch.stack(test_dataset[:][:-1]).cuda()).detach().cpu().numpy()\n",
    "test_labels = test_dataset[:][-1].detach().cpu().numpy()\n",
    "\n",
    "# Train Logistic Classifier\n",
    "clf = LogisticRegression(max_iter=200).fit(train_embeds, train_labels)\n",
    "score = clf.score(test_embeds, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rKl16Y8s3l7Y",
    "outputId": "878d4697-aa22-445a-d4a5-bc62a663372b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BYAcarbw1aJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#MI Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNUlLl-Sw4u1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can estimate the MI between any two sets of vectors using the Probablistic Classifier approach proposed in [Neural Methods for Point-wise Dependency Estimation](https://arxiv.org/abs/2006.05553)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y3i9XEAx8hR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Simple dataset for constructing paired data\n",
    "\n",
    "class PairedDataset(Dataset):\n",
    "  def __init__(self, data_A, data_B):\n",
    "    self.data_A = data_A.float()\n",
    "    self.data_B = data_B.float()\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.data_A.shape[0]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data_A[idx], self.data_B[idx]\n",
    "\n",
    "  def get_dims(self):\n",
    "    return self.data_A.shape[1], self.data_B.shape[1]\n",
    "\n",
    "\n",
    "def train_critic_paired(critic_model, train_loader, opt_crit, num_epoch=80):\n",
    "    MIs = []\n",
    "    for _iter in range(num_epoch):\n",
    "        for i_batch, (A_batch, B_batch) in enumerate(train_loader):\n",
    "            opt_crit.zero_grad()\n",
    "\n",
    "            x_batch = A_batch.cuda()\n",
    "            y_batch = B_batch.cuda()\n",
    "\n",
    "            scores = critic_model(x_batch, y_batch)\n",
    "            MIs.append(probabilistic_classifier_eval(scores))\n",
    "\n",
    "            negative_loss = probabilistic_classifier_obj(scores)\n",
    "            loss = -negative_loss\n",
    "\n",
    "            loss.backward()\n",
    "            opt_crit.step()\n",
    "\n",
    "            if i_batch%100 == 0:\n",
    "                print('iter: ', _iter, ' i_batch: ', i_batch, ' negative_loss: ', negative_loss.item())\n",
    "\n",
    "    return MIs\n",
    "\n",
    "\n",
    "def eval_MI_paired(critic_model, test_loader):\n",
    "    MIs = []\n",
    "\n",
    "    for i_batch, (A_batch, B_batch) in enumerate(test_loader):\n",
    "\n",
    "        x_batch = A_batch.cuda()\n",
    "        y_batch = B_batch.cuda()\n",
    "\n",
    "        scores = critic_model(x_batch, y_batch)\n",
    "        MIs.append(probabilistic_classifier_eval(scores))\n",
    "\n",
    "    MI = torch.stack(MIs).mean()\n",
    "    print(MI.item())\n",
    "    return MI.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vxbxr9jZ1Xl0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layers = 1\n",
    "activation = 'relu'\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdAjxJKYw3gU",
    "outputId": "1a76d26c-c545-4c01-f1af-54fde67e327f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_A = train_dataset[:][0]\n",
    "data_B = train_dataset[:][1]\n",
    "\n",
    "mi_dataset = PairedDataset(data_A, data_B)\n",
    "mi_loader = DataLoader(mi_dataset,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=batch_size)\n",
    "\n",
    "dim1, dim2 = mi_dataset.get_dims()\n",
    "critic_model = SeparableCritic(x1_dim=dim1, x2_dim=dim2, hidden_dim=hidden_dim,\n",
    "                              embed_dim=embed_dim, layers=layers, activation=activation).cuda()\n",
    "\n",
    "opt_crit = optim.Adam(critic_model.parameters(), lr=lr)\n",
    "\n",
    "train_critic_paired(critic_model, mi_loader, opt_crit, num_epoch=30)\n",
    "MI = eval_MI_paired(critic_model, mi_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UP_E2H4EBnsh",
    "z_gdUqNO5NYM"
   ],
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
