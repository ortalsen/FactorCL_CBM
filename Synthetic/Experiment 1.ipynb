{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b1b8d8-b6c1-4a4d-8531-bcb516ed4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2e1c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe09220e810>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dataset import*\n",
    "from baselines import*\n",
    "from synthetic_concept_model import *\n",
    "from synthetic_coop_model import *\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(7)\n",
    "numpy.random.seed(seed=7)\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479b8138-eebc-41d8-a4a6-bf778329e14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4454ff7e",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb3a5653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current generated data : 0\n",
      "Current generated data : 100\n",
      "Current generated data : 200\n",
      "Current generated data : 300\n",
      "Current generated data : 400\n",
      "Current generated data : 500\n",
      "Current generated data : 600\n",
      "Current generated data : 700\n",
      "Current generated data : 800\n",
      "Current generated data : 900\n"
     ]
    }
   ],
   "source": [
    "feature_dim_info = dict()\n",
    "label_dim_info = dict()\n",
    "transform_dim = 100000\n",
    "\n",
    "intersections = get_intersections(num_modalities=2)\n",
    "\n",
    "feature_dim_info['12'] = 10\n",
    "feature_dim_info['1'] = 6\n",
    "feature_dim_info['2'] = 6\n",
    "\n",
    "label_dim_info['12'] = 10\n",
    "label_dim_info['1'] = 6\n",
    "label_dim_info['2'] = 6\n",
    "num_concepts = 1\n",
    "transforms_2concept = None\n",
    "transforms_2hd = None\n",
    "num_data = 1000\n",
    "noise=0.3\n",
    "pos_prob=0.5\n",
    "total_data, total_labels, total_concepts, total_raw_features = generate_data_concepts(num_data, num_concepts,\n",
    "                                                                                      feature_dim_info,\n",
    "                                                                                      label_dim_info,\n",
    "                                                                                      transform_dim=transform_dim,\n",
    "                                                                                     noise=noise,\n",
    "                                                                                     pos_prob=pos_prob)\n",
    "\n",
    "# Data splitting & loading\n",
    "\n",
    "dataset = MultiConcept(total_data, total_labels, total_concepts, 0)\n",
    "batch_size = 100\n",
    "trainval_dataset, test_dataset = torch.utils.data.random_split(dataset,  \n",
    "                                                            [int(0.5 * num_data), num_data - int(0.5 * num_data)])\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainval_dataset,\n",
    "                                                           [int(0.8 * len(trainval_dataset)), len(trainval_dataset) - int(0.8 * len(trainval_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4059c6-b3f0-4fc7-a4c4-291f4e518a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_dim = 101024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f31d4dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a388f33-7b36-4909-9e60-3b3293251cd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scenario 1 \n",
    "One known concept $c_1$ derived from information components $W_{U_1}, W_s$. Label $Y$ is composed of information components $y=f(W_{U_1}, W_s, W_{U_2})$. We try to recover $W_{U_2}$ by $\\arg \\max_{Z_x} I(Z_x;Y|Z_{c_1})$, assuming that $Z_{c_1}$ represents $\\{W_{U_1}, W_s\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f075e2-48aa-452c-8e66-aad5ee3a62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "!!! CHANGE THE train_concept_encoder AND  train_concept_informed_model FUNCTIONS IF NEEDED!!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def factorCBM_exp1(train_dataset, test_dataset, concept_encoder, model, device, num_eval=10, save_path='./results'):\n",
    "\n",
    "    acc_list, pre_list, recall_list, f1_list = [], [], [], []\n",
    "    # teval = tqdm(range(num_eval))\n",
    "    for idx in range(num_eval):\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
    "                          batch_size=batch_size)\n",
    "        val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False)\n",
    "        # train concpet encoder\n",
    "        trained_concept_encoder = train_concept_encoder(concept_encoder, train_loader,val_loader, transform_dim, device, 1e-5, 1e-5, 25, 3, '../trained_models')\n",
    "        # train concept informed model\n",
    "        trained_concept_informed_model = train_concept_informed_model(trained_concept_encoder, model, train_loader, val_loader, 100, device, 1e-5, 25, 3, '../trained_models')\n",
    "        \n",
    "        train_embeds_1 = trained_concept_encoder.get_embedding(torch.stack([sample[0] for sample in  train_dataset]).to(device)).detach().cpu().numpy()\n",
    "        train_embeds_2 = trained_concept_informed_model.get_embedding(torch.stack([sample[0] for sample in  train_dataset]).to(device)).detach().cpu().numpy()\n",
    "        train_embeds = np.concatenate((train_embeds_1, train_embeds_2), axis=1) #train_embeds_2 #\n",
    "        train_labels = np.array([sample[-1].item() for sample in  train_dataset])\n",
    "\n",
    "        test_embeds_1 = trained_concept_encoder.get_embedding(torch.stack([sample[0] for sample in  test_dataset]).to(device)).detach().cpu().numpy()\n",
    "        test_embeds_2 = trained_concept_informed_model.get_embedding(torch.stack([sample[0] for sample in  test_dataset]).to(device)).detach().cpu().numpy()\n",
    "        test_embeds = np.concatenate((test_embeds_1, test_embeds_2), axis=1) #test_embeds_2 #\n",
    "        test_labels = np.array([sample[-1].item() for sample in  test_dataset])\n",
    "\n",
    "        clf = LogisticRegression(max_iter=1000).fit(train_embeds, train_labels)\n",
    "        predictions = clf.predict(test_embeds)\n",
    "        \n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        precision = precision_score(test_labels, predictions)\n",
    "        recall = recall_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions)\n",
    "        \n",
    "        acc_list.append(accuracy)\n",
    "        pre_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    dict_results = {'accuracy':acc_list,\n",
    "                    'precision':pre_list,\n",
    "                    'recall':recall_list,\n",
    "                    'f1_score':f1_list}\n",
    "    df_results = pd.DataFrame(data=dict_results)\n",
    "    \n",
    "    print(f'Accuracy:{df_results.accuracy.mean():0.3f} \\u00B1 {2*df_results.accuracy.std():0.3f}')\n",
    "    print(f'Precision:{df_results.precision.mean():0.3f} \\u00B1 {2*df_results.precision.std():0.3f}')\n",
    "    print(f'Recall:{df_results.recall.mean():0.3f} \\u00B1 {2*df_results.recall.std():0.3f}')\n",
    "    print(f'F1-score:{df_results.f1_score.mean():0.3f} \\u00B1 {2*df_results.f1_score.std():0.3f}')\n",
    "    \n",
    "    directory = save_path + '/' + time.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    timestr = time.strftime(\"%H%M%S\")\n",
    "    file_path = directory +  '/factorCBM_exp1_'+ str(num_eval) + '_' + timestr +'.csv'\n",
    "    df_results.to_csv(file_path)\n",
    "    \n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e160d497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_dim = 512\n",
    "embed_dim = 50 \n",
    "concept_encoder = ConceptEncoder(transform_dim, embed_dim, 1, hidden_dim).to(device)\n",
    "model = ConceptCLSUP_full_concept(transform_dim, embed_dim, 2, hidden_dim, embed_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82079a7-61ff-4130-92a9-235680343ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69:   0%|          | 69/100000 [00:18<6:30:16,  4.27it/s, loss=2e-5]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69:   0%|          | 69/100000 [00:19<7:40:12,  3.62it/s, loss=2e-5]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s, loss=-3.35]\n",
      "Epoch 6:   0%|          | 6/100000 [00:01<6:30:10,  4.27it/s, loss=0.000484] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 6/100000 [00:02<10:52:39,  2.55it/s, loss=0.000484]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s, loss=-12.2]\n",
      "Epoch 6:   0%|          | 6/100000 [00:01<6:14:54,  4.45it/s, loss=0.000404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 6/100000 [00:02<10:45:54,  2.58it/s, loss=0.000404]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s, loss=-33.9]\n",
      "Epoch 3:   0%|          | 3/100000 [00:01<7:27:37,  3.72it/s, loss=0.000639]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<13:42:21,  2.03it/s, loss=0.000639]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:26<00:00,  3.72it/s, loss=-80.5]\n",
      "Epoch 12:   0%|          | 12/100000 [00:03<6:37:55,  4.19it/s, loss=0.0002]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 12/100000 [00:03<9:04:44,  3.06it/s, loss=0.0002]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s, loss=-149]\n",
      "Epoch 3:   0%|          | 3/100000 [00:01<10:44:15,  2.59it/s, loss=0.0018]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:02<19:03:02,  1.46it/s, loss=0.0018]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:28<00:00,  3.57it/s, loss=-265]\n",
      "Epoch 3:   0%|          | 3/100000 [00:01<7:56:30,  3.50it/s, loss=0.00121]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<16:49:42,  1.65it/s, loss=0.00121]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s, loss=-519]\n",
      "Epoch 6:   0%|          | 6/100000 [00:01<5:46:59,  4.80it/s, loss=0.000368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 6/100000 [00:02<10:36:40,  2.62it/s, loss=0.000368]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:26<00:00,  3.82it/s, loss=-787]\n",
      "Epoch 12:   0%|          | 12/100000 [00:03<7:02:39,  3.94it/s, loss=9.55e-5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 12/100000 [00:04<9:51:00,  2.82it/s, loss=9.55e-5]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:26<00:00,  3.83it/s, loss=-1.28e+3]\n",
      "Epoch 3:   0%|          | 3/100000 [00:01<11:26:51,  2.43it/s, loss=0.0015]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:02<21:30:50,  1.29it/s, loss=0.0015]\n",
      "Epoch 99: 100%|██████████| 100/100 [00:26<00:00,  3.76it/s, loss=-1.8e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.850 ± 0.031\n",
      "Precision:0.813 ± 0.056\n",
      "Recall:0.901 ± 0.019\n",
      "F1-score:0.854 ± 0.024\n"
     ]
    }
   ],
   "source": [
    "results = factorCBM_exp1(train_dataset, test_dataset, concept_encoder, model, device, num_eval=10, save_path='./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e909336-9d93-408c-9fd8-ff142887a7bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scenario 2\n",
    "\n",
    "Use both the supervised loss and the Info_club constraint to minimize the mutual information between the learned representation and c, then concatenate c to the learned representation and train everything end-to-end.\n",
    "\n",
    "$\\mathop{\\arg \\min}\\limits_{\\theta , \\phi} \\mathcal{L}\\bigl( y, f_{\\theta}(g_{\\phi}(x),c)\\bigr) + \\lambda Info_{NCE\\_CLUB} \\bigl( g_{\\phi}(x);c \\bigr)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58eedeec-dc27-49bc-a6d5-cea36af8a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "!!! CHANGE THE train_concept_encoder AND  train_concept_informed_model FUNCTIONS IF NEEDED!!!\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "class ConceptCLSUP_Sc2(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, embed_dim, layers=2, activation='relu', lr=1e-4, concept_dim = 1):\n",
    "        super(ConceptCLSUP_Sc2, self).__init__()\n",
    "        self.critic_hidden_dim = 512\n",
    "        self.critic_layers = 1\n",
    "        self.critic_activation = 'relu'\n",
    "\n",
    "        # encoders\n",
    "        self.backbone = mlp(x_dim, hidden_dim, embed_dim, layers, activation)\n",
    "        self.linears_infonce = mlp(embed_dim, embed_dim, embed_dim, 1, activation) \n",
    "        self.y_projection = mlp(embed_dim + concept_dim, embed_dim, 1, 1, activation)\n",
    "\n",
    "        # critics\n",
    "        self.club_critic = CLUBInfoNCECritic(embed_dim + x_dim, concept_dim, self.critic_hidden_dim, self.critic_layers, self.critic_activation)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        # compute embedding\n",
    "        z = self.linears_infonce(self.backbone(x))\n",
    "        # compute critic scores\n",
    "        club_infonce_score = self.club_critic(torch.cat([z, x], dim=-1), c)\n",
    "        y_encoding = self.y_projection(torch.cat([z,c], dim=-1))\n",
    "        \n",
    "        return club_infonce_score, y_encoding\n",
    "\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def get_logits(self, x, c):\n",
    "        z = self.linears_infonce(self.backbone(x))\n",
    "        return self.y_projection(torch.cat([z,c], dim=-1))\n",
    "    \n",
    "    def get_backbone(self):\n",
    "        return self.backbone\n",
    "    \n",
    "    \n",
    "def train_concept_informed_model_sc2(concept_encoder, model, train_loader,val_loader, num_epochs, device, lr, lamb, log_interval,\n",
    "                          save_interval, save_path):\n",
    "\n",
    "    # concept_encoder.eval()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    label_loss_func = torch.nn.BCELoss()\n",
    "    best_val_err = torch.tensor(1e7)\n",
    "    tepoch = tqdm(range(num_epochs))\n",
    "    for epoch in tepoch:\n",
    "        tepoch.set_description(f\"Epoch {epoch}\")\n",
    "        model.train()\n",
    "        for batch_idx, (data, concept, target) in enumerate(train_loader):\n",
    "            data, concept, target = data.to(device), concept.to(device) ,target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            c, z_c = concept_encoder(data)\n",
    "            MI_loss, y_logits = model(data, c) #oncept\n",
    "            label_loss = label_loss_func(torch.sigmoid(y_logits), target.float())\n",
    "            loss = label_loss + lamb * MI_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "            # gc.collect()\n",
    "            \n",
    "        tepoch.set_postfix(loss=loss.item())\n",
    "        if epoch % save_interval == 0:\n",
    "            val_err = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (data, concept, target) in enumerate(val_loader):\n",
    "                    data, concept, target = data.to(device), concept.to(device), target.to(device)\n",
    "                    c , z_c = concept_encoder(data)\n",
    "                    # output = model(data, c, target) #z_c\n",
    "                    MI_loss, y_logits = model(data, c)#oncept\n",
    "                    label_loss = label_loss_func(torch.sigmoid(y_logits), target.float())\n",
    "                    loss = label_loss + lamb * MI_loss\n",
    "                    val_err += loss\n",
    "                val_err = val_err / len(val_loader)\n",
    "            if val_err < best_val_err:\n",
    "                best_val_err = val_err\n",
    "\n",
    "            else:\n",
    "                print('Val loss did not improve')\n",
    "                torch.save(model.state_dict(), os.path.join(save_path, 'concept_informed_model.pth'))\n",
    "                return model\n",
    "    return model\n",
    "\n",
    "def factorCBM_exp1_Sc2(train_dataset, test_dataset, concept_encoder, model, device, num_eval=10, save_path='./results'):\n",
    "\n",
    "    acc_list, pre_list, recall_list, f1_list = [], [], [], []\n",
    "    # teval = tqdm(range(num_eval))\n",
    "    for idx in range(num_eval):\n",
    "        train_loader = DataLoader(train_dataset, shuffle=True, drop_last=True,\n",
    "                          batch_size=batch_size)\n",
    "        val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "        test_loader = DataLoader(test_dataset, shuffle=False, drop_last=False)\n",
    "        # train concpet encoder\n",
    "        trained_concept_encoder = train_concept_encoder(concept_encoder, train_loader,val_loader, 100, device, 1e-5, 1e-5, 25, 3, '../trained_models')\n",
    "        # train concept informed model concept_encoder\n",
    "        trained_concept_informed_model = train_concept_informed_model_sc2(trained_concept_encoder, model, train_loader, val_loader, num_epochs=100, device=device,\n",
    "                                                                          lr=1e-5, lamb=0.5, log_interval = 25, save_interval = 3, save_path ='../trained_models')\n",
    "        \n",
    "        test_embeds =  torch.stack([sample[0] for sample in  test_dataset]).to(device)\n",
    "        test_concepts = torch.tensor([sample[1] for sample in  test_dataset]).unsqueeze(1).to(device)\n",
    "        test_labels = np.array([sample[-1].item() for sample in  test_dataset])\n",
    "\n",
    "        \n",
    "        out = trained_concept_informed_model.get_logits(test_embeds, test_concepts)\n",
    "        \n",
    "        predictions = torch.sigmoid(out).round().detach().cpu().numpy()\n",
    "        \n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        precision = precision_score(test_labels, predictions)\n",
    "        recall = recall_score(test_labels, predictions)\n",
    "        f1 = f1_score(test_labels, predictions)\n",
    "        \n",
    "        acc_list.append(accuracy)\n",
    "        pre_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    dict_results = {'accuracy':acc_list,\n",
    "                    'precision':pre_list,\n",
    "                    'recall':recall_list,\n",
    "                    'f1_score':f1_list}\n",
    "    df_results = pd.DataFrame(data=dict_results)\n",
    "    \n",
    "    print(f'Accuracy:{df_results.accuracy.mean():0.3f} \\u00B1 {2*df_results.accuracy.std():0.3f}')\n",
    "    print(f'Precision:{df_results.precision.mean():0.3f} \\u00B1 {2*df_results.precision.std():0.3f}')\n",
    "    print(f'Recall:{df_results.recall.mean():0.3f} \\u00B1 {2*df_results.recall.std():0.3f}')\n",
    "    print(f'F1-score:{df_results.f1_score.mean():0.3f} \\u00B1 {2*df_results.f1_score.std():0.3f}')\n",
    "    \n",
    "    directory = save_path + '/' + time.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    timestr = time.strftime(\"%H%M%S\")\n",
    "    file_path = directory +  '/factorCBM_exp1_Sc2_'+ str(num_eval) + '_' + timestr +'.csv'\n",
    "    df_results.to_csv(file_path)\n",
    "    \n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d678604-9f44-4a0a-a915-91e2c9769cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "hidden_dim = 512\n",
    "embed_dim = 50\n",
    "concept_encoder = ConceptEncoder(transform_dim, embed_dim, 1, hidden_dim).to(device)\n",
    "model = ConceptCLSUP_Sc2(transform_dim, hidden_dim, embed_dim, 2, 'relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b67dfd6-c1de-4f86-87c0-90749b2fbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78:   0%|          | 78/100000 [00:19<5:48:22,  4.78it/s, loss=1.07e-5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78:   0%|          | 78/100000 [00:19<6:56:00,  4.00it/s, loss=1.07e-5]\n",
      "Epoch 99: 100%|██████████| 100/100 [02:10<00:00,  1.31s/it, loss=-.0355] \n",
      "Epoch 12:   0%|          | 12/100000 [00:03<6:45:23,  4.11it/s, loss=0.000417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 12/100000 [00:03<8:37:30,  3.22it/s, loss=0.000417]\n",
      "Epoch 39:  39%|███▉      | 39/100 [00:51<01:17,  1.27s/it, loss=-.0744]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39:  39%|███▉      | 39/100 [00:52<01:22,  1.35s/it, loss=-.0744]\n",
      "Epoch 3:   0%|          | 3/100000 [00:00<6:19:49,  4.39it/s, loss=0.00208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<12:14:56,  2.27it/s, loss=0.00208]\n",
      "Epoch 12:  12%|█▏        | 12/100 [00:16<01:51,  1.26s/it, loss=-.0832]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:  12%|█▏        | 12/100 [00:17<02:09,  1.47s/it, loss=-.0832]\n",
      "Epoch 3:   0%|          | 3/100000 [00:00<6:08:40,  4.52it/s, loss=0.00102]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<11:18:15,  2.46it/s, loss=0.00102]\n",
      "Epoch 3:   3%|▎         | 3/100 [00:05<02:01,  1.25s/it, loss=-.0894]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   3%|▎         | 3/100 [00:06<03:14,  2.01s/it, loss=-.0894]\n",
      "Epoch 9:   0%|          | 9/100000 [00:02<6:15:45,  4.44it/s, loss=0.000391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   0%|          | 9/100000 [00:02<8:53:41,  3.12it/s, loss=0.000391]\n",
      "Epoch 3:   3%|▎         | 3/100 [00:05<02:01,  1.25s/it, loss=-.0962]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   3%|▎         | 3/100 [00:06<03:15,  2.02s/it, loss=-.0962]\n",
      "Epoch 3:   0%|          | 3/100000 [00:00<6:31:24,  4.26it/s, loss=0.000872]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<11:44:51,  2.36it/s, loss=0.000872]\n",
      "Epoch 9:   9%|▉         | 9/100 [00:12<01:54,  1.26s/it, loss=-.12]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:   9%|▉         | 9/100 [00:13<02:19,  1.53s/it, loss=-.12]\n",
      "Epoch 3:   0%|          | 3/100000 [00:00<6:49:32,  4.07it/s, loss=0.00107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<12:40:59,  2.19it/s, loss=0.00107]\n",
      "Epoch 6:   6%|▌         | 6/100 [00:09<02:01,  1.29s/it, loss=-.134] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   6%|▌         | 6/100 [00:10<02:39,  1.69s/it, loss=-.134]\n",
      "Epoch 6:   0%|          | 6/100000 [00:01<6:35:52,  4.21it/s, loss=0.000574]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 6/100000 [00:02<9:17:51,  2.99it/s, loss=0.000574]\n",
      "Epoch 3:   3%|▎         | 3/100 [00:05<02:02,  1.26s/it, loss=-.133]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   3%|▎         | 3/100 [00:06<03:16,  2.02s/it, loss=-.133]\n",
      "Epoch 3:   0%|          | 3/100000 [00:00<6:56:45,  4.00it/s, loss=0.000872]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 3/100000 [00:01<11:57:18,  2.32it/s, loss=0.000872]\n",
      "Epoch 3:   3%|▎         | 3/100 [00:05<02:04,  1.28s/it, loss=-.111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   3%|▎         | 3/100 [00:06<03:19,  2.05s/it, loss=-.111]\n",
      "Epoch 12:   0%|          | 12/100000 [00:03<6:31:45,  4.25it/s, loss=0.000184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12:   0%|          | 12/100000 [00:03<8:10:15,  3.40it/s, loss=0.000184]\n",
      "Epoch 6:   6%|▌         | 6/100 [00:08<01:58,  1.27s/it, loss=-.137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:   6%|▌         | 6/100 [00:09<02:35,  1.66s/it, loss=-.137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.848 ± 0.021\n",
      "Precision:0.918 ± 0.038\n",
      "Recall:0.756 ± 0.082\n",
      "F1-score:0.828 ± 0.035\n"
     ]
    }
   ],
   "source": [
    "results = factorCBM_exp1_Sc2(train_dataset, test_dataset, concept_encoder, model, device, num_eval=10, save_path='./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575e2f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline 1 (logistic regression on $x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7c9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation 9: 100%|██████████| 10/10 [02:45<00:00, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.864 ± 0.000\n",
      "Precision:0.876 ± 0.000\n",
      "Recall:0.840 ± 0.000\n",
      "F1-score:0.858 ± 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_1 = baseline_1(train_dataset, test_dataset, num_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5d0a5-03be-402e-9a56-c3f50811e89f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline 2 (Supervised Representation Learning on $x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6046bbeb-7b24-47c3-9d94-1c5af8c0f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400:  40%|████      | 400/1000 [01:29<02:13,  4.49it/s, loss=1.97e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 900:  90%|█████████ | 900/1000 [03:21<00:22,  4.46it/s, loss=4.59e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [03:49<00:00,  4.36it/s, loss=2.7e-6] \n",
      "Epoch 900:  90%|█████████ | 900/1000 [03:30<00:23,  4.28it/s, loss=3.41e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 800:  80%|████████  | 800/1000 [03:04<00:46,  4.34it/s, loss=2.73e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 800:  80%|████████  | 800/1000 [03:08<00:47,  4.25it/s, loss=3.58e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 900:  90%|█████████ | 900/1000 [03:27<00:23,  4.34it/s, loss=4.13e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [01:58<01:58,  4.23it/s, loss=8.68e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [03:52<00:00,  4.29it/s, loss=2.65e-6]\n",
      "Epoch 700:  70%|███████   | 700/1000 [02:45<01:10,  4.24it/s, loss=2.75e-6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n",
      "Accuracy:0.865 ± 0.011\n",
      "Precision:0.887 ± 0.019\n",
      "Recall:0.829 ± 0.044\n",
      "F1-score:0.857 ± 0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_2 = baseline_2(train_dataset, val_dataset, test_dataset, transform_dim=transform_dim, batch_size=batch_size, num_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7c1c8-721f-4eca-a571-73a29d83a521",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18f13c-0240-4a48-ac24-419fdc1900c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Logistic Regression on $x,c_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b94ad4d0-8c54-4dcf-a4dd-b4aa6c4fe866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation 9: 100%|██████████| 10/10 [02:44<00:00, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.870 ± 0.000\n",
      "Precision:0.884 ± 0.000\n",
      "Recall:0.844 ± 0.000\n",
      "F1-score:0.864 ± 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "resuts_3_A = baseline_3_A(train_dataset, test_dataset, num_eval=10, save_path='./results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94feeba-44bd-4ffb-98d1-8c419385b4e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (Supervised Representation Learning on $x,c_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f184415-dec1-4ab9-bba8-7120f30de237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:18<01:32,  4.34it/s, loss=5.88e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 800:  80%|████████  | 800/1000 [03:06<00:46,  4.29it/s, loss=2.17e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 700:  70%|███████   | 700/1000 [02:42<01:09,  4.31it/s, loss=5.75e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [03:49<00:00,  4.37it/s, loss=4.57e-6]\n",
      "Epoch 999: 100%|██████████| 1000/1000 [03:50<00:00,  4.33it/s, loss=4.95e-6]\n",
      "Epoch 700:  70%|███████   | 700/1000 [02:43<01:10,  4.28it/s, loss=3.8e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [01:56<01:56,  4.28it/s, loss=1e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 800:  80%|████████  | 800/1000 [03:04<00:46,  4.33it/s, loss=3.67e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 800:  80%|████████  | 800/1000 [03:07<00:46,  4.26it/s, loss=2.76e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [03:52<00:00,  4.29it/s, loss=3.24e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.865 ± 0.007\n",
      "Precision:0.885 ± 0.022\n",
      "Recall:0.832 ± 0.035\n",
      "F1-score:0.857 ± 0.010\n"
     ]
    }
   ],
   "source": [
    "results_3_b = baseline_3_B(train_dataset, val_dataset, test_dataset, transform_dim=transform_dim, batch_size=batch_size, num_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1e358-1f82-4801-af13-d05a847ce8a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline 4 (Multi-Task Learning with Concepts $x \\rightarrow y, c_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5037329a-68f2-48a3-acd1-1f4858b5d04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:15<01:30,  4.43it/s, loss=0.000589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 900:  90%|█████████ | 900/1000 [03:31<00:23,  4.26it/s, loss=5.18e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [25:39<25:39,  3.08s/it, loss=0.00305]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 500:  50%|█████     | 500/1000 [04:51<04:51,  1.71it/s, loss=0.00045] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:22<01:35,  4.21it/s, loss=0.00101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 700:  70%|███████   | 700/1000 [02:45<01:11,  4.22it/s, loss=8.21e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:20<01:33,  4.26it/s, loss=7.74e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [01:57<01:57,  4.26it/s, loss=0.00461] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [04:16<04:16,  1.95it/s, loss=0.00124] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 800:  80%|████████  | 800/1000 [30:34<07:38,  2.29s/it, loss=0.000284]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n",
      "Accuracy:0.866 ± 0.007\n",
      "Precision:0.888 ± 0.016\n",
      "Recall:0.830 ± 0.011\n",
      "F1-score:0.858 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "results_4 = baseline_4(train_dataset, val_dataset, test_dataset, transform_dim=transform_dim, batch_size=batch_size, num_eval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f6e45c-2ffe-4947-986a-0602d8f5d0e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline 5 (Pre-Training with Concepts $x \\rightarrow c_1, x \\rightarrow y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b912cd7-42d6-43fa-8424-671e08e2641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [01:58<01:58,  4.23it/s, loss=0.000129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 900:  90%|█████████ | 900/1000 [03:40<00:24,  4.07it/s, loss=3.7e-6]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:06<02:06,  3.94it/s, loss=0.000329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [04:11<00:00,  3.97it/s, loss=4.82e-6]\n",
      "Epoch 500:  50%|█████     | 500/1000 [02:10<02:10,  3.83it/s, loss=1.66e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999: 100%|██████████| 1000/1000 [04:10<00:00,  4.00it/s, loss=1.83e-6]\n",
      "Epoch 500:  50%|█████     | 500/1000 [02:05<02:05,  3.97it/s, loss=0.000196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:01<02:01,  4.11it/s, loss=1.78e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:03<02:03,  4.04it/s, loss=0.00135] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 700:  70%|███████   | 700/1000 [02:49<01:12,  4.14it/s, loss=6.47e-6] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:28<01:39,  4.03it/s, loss=1.53e-7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400:  40%|████      | 400/1000 [01:39<02:28,  4.04it/s, loss=2.51e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:04<02:04,  4.02it/s, loss=0.00043] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:04<02:04,  4.01it/s, loss=2.04e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:09<02:09,  3.88it/s, loss=0.00291] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400:  40%|████      | 400/1000 [01:37<02:26,  4.09it/s, loss=2.44e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:05<02:05,  4.00it/s, loss=0.000461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 400:  40%|████      | 400/1000 [01:43<02:34,  3.88it/s, loss=2.4e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 500:  50%|█████     | 500/1000 [02:07<02:07,  3.92it/s, loss=8.47e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 600:  60%|██████    | 600/1000 [02:30<01:40,  3.98it/s, loss=8.89e-6] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss did not improve\n",
      "Accuracy:0.865 ± 0.018\n",
      "Precision:0.882 ± 0.071\n",
      "Recall:0.839 ± 0.136\n",
      "F1-score:0.857 ± 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_5 = baseline_5(train_dataset, val_dataset, test_dataset,w5=0, transform_dim=transform_dim, batch_size=batch_size, num_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738cfac9-dd11-4960-a047-199455cece76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c189f109-717a-4fe7-9e8c-da05679cc42a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c31978-f194-4495-8b1e-703b7e0a71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcac8f4-b090-4c17-a9fd-f8187652099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'factorCBM_exp1', w5_list=['1', '2', '3','5', '7', '10', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc9bda-cc76-4e15-9526-313c02a1b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'baseline_2', w5_list=['1', '2', '3','5', '7', '10', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abeacec-2baa-41bd-851a-e52ca59ec879",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'baseline_3_A', w5_list=['1', '2', '3','5', '7', '10', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904beeb-fd28-43f2-9c5a-41e488734b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'baseline_3_B', w5_list=['1', '2','3','5', '7', '10', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25451f4f-52ef-432d-ab71-50b6e143c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'baseline_4', w5_list=['1','3','5', '10', '12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64e73c-860b-44b0-9c9a-96f64986b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_w5_curves(baseline= 'baseline_5', w5_list=['1', '3','5', '10', '12'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
